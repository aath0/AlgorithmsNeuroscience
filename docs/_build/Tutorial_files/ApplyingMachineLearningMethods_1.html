---
redirect_from:
  - "/tutorial-files/applyingmachinelearningmethods-1"
interact_link: content/Tutorial_files/ApplyingMachineLearningMethods_1.ipynb
kernel_name: python3
has_widgets: false
title: |-
  Participant Level Analysis
prev_page:
  url: /Tutorial_files/DatasetConstruction.html
  title: |-
    Constructing Dataset
next_page:
  url: /Tutorial_files/ApplyingMachineLearningMethods_2.html
  title: |-
    Group Level Analysis
suffix: .ipynb

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tutorial-#4:-Applying-Machine-Learning-Methods-to-EEG-Data-on-Participant-Level">Tutorial #4: Applying Machine Learning Methods to EEG Data on Participant Level<a class="anchor-link" href="#Tutorial-#4:-Applying-Machine-Learning-Methods-to-EEG-Data-on-Participant-Level"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this tutorial, machine learning methods that are commonly preferred for EEG analysis will be discussed. Additionally different techinques for approaching a classification problem on eeg data of 1 participant will be demonstrated.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Dataset:">Dataset:<a class="anchor-link" href="#Dataset:"> </a></h5><p>As the dataset for this tutorial, 'Emotion-Antecedent Appraisal Checks:
EEG and EMG data sets for Novelty and Pleasantness' selected. In this dataset, there are 26 participants, each have varying number of trials. There are three main categories as Target, Novel and Familar. Athough 70% of all images are in familiar category, 20% of them belongs to novel category and the rest is Target, each category has equal portion of Pleasant, Unpleasant and Neutral color images. If an image among 'Pleasant' images is selected and if it is also familiar to the participant, then the trial that is conducted with this image have 'FP' (Familiar-Pleasant) label. 
Therefore, in total there are 6 categories in this dataset. However number of categories may be changed by combining trials with the same familiarity level or the same pleasantness level.</p>
<p>Since familar images forms the 70% of the dataset, trials with familiar pictures will be used throughout this tutorial to analyse effects of stimuli with different pleasantness levels on eeg.</p>
<p>Note that, only one participant will be used in this tutorial.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Machine-Learning-Methods:">Machine Learning Methods:<a class="anchor-link" href="#Machine-Learning-Methods:"> </a></h5><p>For modelling eeg data, there are three common methods: Support Vector Machines, Linear Discriminant Analysis and Logistic Regression. These methods will be employed for modeling two class problems. In the end, we will get 3 models per method.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># For elimiating warnings</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Load necessary libraries</span>
<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">from</span> <span class="nn">mne.decoding</span> <span class="k">import</span> <span class="n">Vectorizer</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_recall_fscore_support</span>

<span class="c1"># Models</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="k">import</span> <span class="n">LinearDiscriminantAnalysis</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As the first step, load epoch data from file. Please note that originally, this dataset is given in csv file. However it cannot be used directly as it is with MNE library. Therefore, if you want to proceed this tutorial, firstly go through the tutorial named 'study1'.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_file</span> <span class="o">=</span> <span class="s1">&#39;../../study1/study1_eeg/epochdata/P-01&#39;</span>

<span class="c1"># Read the EEG epochs:</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="n">mne</span><span class="o">.</span><span class="n">read_epochs</span><span class="p">(</span><span class="n">data_file</span> <span class="o">+</span> <span class="s1">&#39;.fif&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Reading ../../study1/study1_eeg/epochdata/P-01.fif ...
    Found the data of interest:
        t =       0.00 ...    1496.09 ms
        0 CTF compensation matrices available
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>&lt;ipython-input-180-a55ec86bce5e&gt;:4: RuntimeWarning: This filename (../../study1/study1_eeg/epochdata/P-01.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz
  epochs = mne.read_epochs(data_file + &#39;.fif&#39;)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>484 matching events found
No baseline correction applied
Not setting metadata
0 projection items activated
484
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs</span><span class="o">.</span><span class="n">event_id</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;FU&#39;: 0, &#39;FN&#39;: 1, &#39;FP&#39;: 2, &#39;NN&#39;: 3, &#39;NP&#39;: 4, &#39;NU&#39;: 5}</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Keep familiar events only. Among FU, FN and FP events, create datasets with all possible event type pairs to build models for binary classification.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs_UN</span> <span class="o">=</span> <span class="n">epochs</span><span class="p">[</span><span class="s1">&#39;FU&#39;</span><span class="p">,</span> <span class="s1">&#39;FN&#39;</span><span class="p">]</span>
<span class="n">epochs_UP</span> <span class="o">=</span> <span class="n">epochs</span><span class="p">[</span><span class="s1">&#39;FU&#39;</span><span class="p">,</span> <span class="s1">&#39;FP&#39;</span><span class="p">]</span>
<span class="n">epochs_NP</span> <span class="o">=</span> <span class="n">epochs</span><span class="p">[</span><span class="s1">&#39;FN&#39;</span><span class="p">,</span> <span class="s1">&#39;FP&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Task-#1:--Classification-between-Unpleasant-and-Neutral-Events">Task #1:  Classification between Unpleasant and Neutral Events<a class="anchor-link" href="#Task-#1:--Classification-between-Unpleasant-and-Neutral-Events"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Get data and the label for the dataset with unpleasant and neutral events.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Dataset with unpleasant and neutral events</span>
<span class="n">data_UN</span> <span class="o">=</span> <span class="n">epochs_UN</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span>
<span class="n">labels_UN</span> <span class="o">=</span> <span class="n">epochs_UN</span><span class="o">.</span><span class="n">events</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Split dataset into two sub-datasets as training set and test set with 70 - 30 ratio.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_data_UN</span><span class="p">,</span> <span class="n">test_data_UN</span><span class="p">,</span> <span class="n">labels_train_UN</span><span class="p">,</span> <span class="n">labels_test_UN</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data_UN</span><span class="p">,</span> <span class="n">labels_UN</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Construct the pipeline with make_pipeline() function of sklearn library. The steps should be defined in the order of execution. Apart from the classifier, Vectorizer() and StandardScaler() will be used. The purpose of using Vectorizer is to convert eeg data from (n_epochs, n_channels, n_times) structure to a vector of (samples x channels) form.</p>
<p>After having vectorized data, StandardScaler standardizes data feature-wise by following standard score technique which has the formulation of z = (x - u) / s. In this formula, u is the mean of the feature and s is the standard deviation of the same feature. By applying this technique, each feature's mean and standard deviation will become zero and one respectively. Standardization of features, which are eeg channels in our case, prevent domination of a channel(or a feature) just becuase it contains larger variation.</p>
<p>The final parameter of make_pipeline() will be the machine learning model. In the folowing example, the selected model is support vector machine model with rbf kernel and penalty parameter C=1.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf_svm_0</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">Vectorizer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If the hyperparameters for the classifier is determined in advance, they can be directly fixed as in above cell. However, usually it is quite difficult to determine optimal hyperparameters before testing different values for each parameter. If we test each parameter manually, we end up with another issue named overfitting. In such a case we would train the classifier with training set and test the performance on test set. So, we optimized parameters on the test set. In general, test set is smaller that training set and it may change when the trained classifier is being started to use in real systems. Therefore, having an overfitted model to test set would not provide a good generalization.</p>
<p>For this problem cross validation would be a solution. In this approach, training set is devided into equally sized folds and trials run on different folds. In this way, hypeparameters will not be optimized on just one dataset, instead different chuncks of data will be used for hyperparameter optimization. Note that, at each trial one fold will be excluded from the training set and excluded fold will be used as test set during evaluation.</p>
<p>For cross validation, sklearn libarary has a method cross_val_score which runs cross validation and calculates and returns the accuracy of each fold. Number of folds is parameter for this function but as a heuristic, the 5-fold or 10-fold cross validation is preferred.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf_svm_0</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">Vectorizer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf_svm_0</span><span class="p">,</span> <span class="n">data_UN</span><span class="p">,</span> <span class="n">labels_UN</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">)):</span>   
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy of &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;th fold is &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracy of 1th fold is 0.6470588235294118

Accuracy of 2th fold is 0.64

Accuracy of 3th fold is 0.76

Accuracy of 4th fold is 0.6326530612244898

Accuracy of 5th fold is 0.673469387755102

</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another option is GridSearchCV which searchs the best performing parameters among the given list of possible parameter values exhaustedly. You can specify the scoring method and cross validation strategy inside GridSearchCV. In the following example StratifiedKFold strategy is selected. The benefit of using this stratefy is that it divides data into folds with approxiamtely same percentage of classes as the whole dataset.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#svm</span>
<span class="n">clf_svm_pip</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">Vectorizer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;svc__kernel&#39;</span><span class="p">:[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">],</span> <span class="s1">&#39;svc__C&#39;</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="n">gs_cv_svm</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">clf_svm_pip</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Train the classifier by passing training data and thier labels to fit() function.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gs_cv_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data_UN</span><span class="p">,</span> <span class="n">labels_train_UN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Parameters: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs_cv_svm</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Score: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs_cv_svm</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.
  DeprecationWarning)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Best Parameters: {&#39;svc__C&#39;: 0.1, &#39;svc__kernel&#39;: &#39;linear&#39;}
Best Score: 0.7011494252873564
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, evaluate the model on test set. With classification_report function you are able to get precision, recall, f1-score and accuracy at the same time. If you want to have accuracy or other metrics separately, you can directly use sklearn's accuracy_score() or precision_recall_fscore_support() functions. If you use precision_recall_fscore_support() with average='macro' parameter, it calculates each metric by averaging all classes without weights.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Prediction</span>
<span class="n">predictions_svm</span> <span class="o">=</span> <span class="n">gs_cv_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data_UN</span><span class="p">)</span>

<span class="c1">#Evaluate</span>
<span class="n">report_svm</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">labels_test_UN</span><span class="p">,</span> <span class="n">predictions_svm</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Unpleasant&#39;</span><span class="p">,</span> <span class="s1">&#39;Neutral&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;SVM Clasification Report:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">report_svm</span><span class="p">))</span>

<span class="n">acc_svm</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels_test_UN</span><span class="p">,</span> <span class="n">predictions_svm</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy of SVM model: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_svm</span><span class="p">))</span>

<span class="n">precision_svm</span><span class="p">,</span><span class="n">recall_svm</span><span class="p">,</span><span class="n">fscore_svm</span><span class="p">,</span><span class="n">support_svm</span><span class="o">=</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">labels_test_UN</span><span class="p">,</span><span class="n">predictions_svm</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision: </span><span class="si">{0}</span><span class="s1">, Recall: </span><span class="si">{1}</span><span class="s1">, f1-score:</span><span class="si">{2}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision_svm</span><span class="p">,</span><span class="n">recall_svm</span><span class="p">,</span><span class="n">fscore_svm</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>SVM Clasification Report:
               precision    recall  f1-score   support

  Unpleasant       0.79      0.59      0.68        37
     Neutral       0.68      0.84      0.75        38

    accuracy                           0.72        75
   macro avg       0.73      0.72      0.71        75
weighted avg       0.73      0.72      0.72        75

Accuracy of SVM model: 0.72
Precision: 0.7332826747720365, Recall: 0.7183499288762447, f1-score:0.7149321266968326
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The same steps can be applied to train any other machine learning models.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The example above classifies unpleasant and neutral events with SVM. In the following cells, Logistic Regression and LDA will be built for the same classification task and then, performance of three different models will be compared.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Logistic Regression</span>
<span class="n">clf_lr_pip</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">Vectorizer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;logisticregression__penalty&#39;</span><span class="p">:[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">]}</span>
<span class="n">gs_cv_lr</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">clf_lr_pip</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="n">gs_cv_lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data_UN</span><span class="p">,</span> <span class="n">labels_train_UN</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Parameters: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs_cv_lr</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Score: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs_cv_lr</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>

<span class="c1">#Predictions</span>
<span class="n">predictions_lr</span> <span class="o">=</span> <span class="n">gs_cv_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data_UN</span><span class="p">)</span>

<span class="c1">#Evaluation</span>
<span class="n">report_lr</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">labels_test_UN</span><span class="p">,</span> <span class="n">predictions_lr</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Unpleasant&#39;</span><span class="p">,</span> <span class="s1">&#39;Neutral&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;LR Clasification Report:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">report_lr</span><span class="p">))</span>

<span class="n">acc_lr</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels_test_UN</span><span class="p">,</span> <span class="n">predictions_lr</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy of LR model: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_lr</span><span class="p">))</span>

<span class="n">precision_lr</span><span class="p">,</span><span class="n">recall_lr</span><span class="p">,</span><span class="n">fscore_lr</span><span class="p">,</span><span class="n">support_lr</span><span class="o">=</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">labels_test_UN</span><span class="p">,</span><span class="n">predictions_lr</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision: </span><span class="si">{0}</span><span class="s1">, Recall: </span><span class="si">{1}</span><span class="s1">, f1-score:</span><span class="si">{2}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision_lr</span><span class="p">,</span><span class="n">recall_lr</span><span class="p">,</span><span class="n">fscore_lr</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
  warnings.warn(CV_WARNING, FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.
  DeprecationWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Best Parameters: {&#39;logisticregression__penalty&#39;: &#39;l1&#39;}
Best Score: 0.7471264367816092
LR Clasification Report:
               precision    recall  f1-score   support

  Unpleasant       0.74      0.62      0.68        37
     Neutral       0.68      0.79      0.73        38

    accuracy                           0.71        75
   macro avg       0.71      0.71      0.70        75
weighted avg       0.71      0.71      0.70        75

Accuracy of LR model: 0.7066666666666667
Precision: 0.7118768328445748, Recall: 0.705547652916074, f1-score:0.7040889526542324
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Linear Discriminant Analysis</span>
<span class="n">clf_lda_pip</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">Vectorizer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LinearDiscriminantAnalysis</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;svd&#39;</span><span class="p">))</span>
<span class="n">clf_lda_pip</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data_UN</span><span class="p">,</span><span class="n">labels_train_UN</span><span class="p">)</span>

<span class="c1">#Predictions</span>
<span class="n">predictions_lda</span> <span class="o">=</span> <span class="n">clf_lda_pip</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data_UN</span><span class="p">)</span>

<span class="c1">#Evaluation</span>
<span class="n">report_lda</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">labels_test_UN</span><span class="p">,</span> <span class="n">predictions_lda</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Unpleasant&#39;</span><span class="p">,</span> <span class="s1">&#39;Neutral&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;LDA Clasification Report:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">report_lda</span><span class="p">))</span>

<span class="n">acc_lda</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels_test_UN</span><span class="p">,</span> <span class="n">predictions_lda</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy of LDA model: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_lda</span><span class="p">))</span>

<span class="n">precision_lda</span><span class="p">,</span><span class="n">recall_lda</span><span class="p">,</span><span class="n">fscore_lda</span><span class="p">,</span><span class="n">support_lda</span><span class="o">=</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">labels_test_UN</span><span class="p">,</span><span class="n">predictions_lda</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision: </span><span class="si">{0}</span><span class="s1">, Recall: </span><span class="si">{1}</span><span class="s1">, f1-score:</span><span class="si">{2}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision_lda</span><span class="p">,</span><span class="n">recall_lda</span><span class="p">,</span><span class="n">fscore_lda</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>LDA Clasification Report:
               precision    recall  f1-score   support

  Unpleasant       0.76      0.68      0.71        37
     Neutral       0.71      0.79      0.75        38

    accuracy                           0.73        75
   macro avg       0.74      0.73      0.73        75
weighted avg       0.74      0.73      0.73        75

Accuracy of LDA model: 0.7333333333333333
Precision: 0.7359307359307359, Recall: 0.732574679943101, f1-score:0.7321428571428572
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.
  warnings.warn(&#34;Variables are collinear.&#34;)
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracies</span><span class="p">,</span> <span class="n">f1_scores</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="n">accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">acc_svm</span><span class="p">,</span> <span class="n">acc_lr</span><span class="p">,</span> <span class="n">acc_lda</span><span class="p">])</span>
<span class="n">f1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">fscore_svm</span><span class="p">,</span> <span class="n">fscore_lr</span><span class="p">,</span> <span class="n">fscore_lda</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Task-#2:--Classification-between-Unpleasant-and-Pleasant-Events">Task #2:  Classification between Unpleasant and Pleasant Events<a class="anchor-link" href="#Task-#2:--Classification-between-Unpleasant-and-Pleasant-Events"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Prepare dataset</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Dataset with unpleasant and pleasant events</span>
<span class="n">data_UP</span> <span class="o">=</span> <span class="n">epochs_UP</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span>
<span class="n">labels_UP</span> <span class="o">=</span> <span class="n">epochs_UP</span><span class="o">.</span><span class="n">events</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">train_data_UP</span><span class="p">,</span> <span class="n">test_data_UP</span><span class="p">,</span> <span class="n">labels_train_UP</span><span class="p">,</span> <span class="n">labels_test_UP</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data_UP</span><span class="p">,</span> <span class="n">labels_UP</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Building SVM, LR and LDA models as in the first example.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># SVM</span>
<span class="n">clf_svm_pip</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">Vectorizer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;svc__kernel&#39;</span><span class="p">:[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">],</span> <span class="s1">&#39;svc__C&#39;</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="n">gs_cv_svm</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">clf_svm_pip</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">gs_cv_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data_UP</span><span class="p">,</span> <span class="n">labels_train_UP</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Parameters: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs_cv_svm</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Score: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs_cv_svm</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>

<span class="c1"># Make prediction</span>
<span class="n">predictions_svm</span> <span class="o">=</span> <span class="n">gs_cv_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data_UP</span><span class="p">)</span>
<span class="c1">#Evaluation</span>
<span class="n">report_svm</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">labels_test_UP</span><span class="p">,</span> <span class="n">predictions_svm</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Unpleasant&#39;</span><span class="p">,</span> <span class="s1">&#39;Pleasant&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;SVM Clasification Report:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">report_svm</span><span class="p">))</span>

<span class="n">acc_svm</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels_test_UP</span><span class="p">,</span> <span class="n">predictions_svm</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy of SVM model: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_svm</span><span class="p">))</span>

<span class="n">precision_svm</span><span class="p">,</span><span class="n">recall_svm</span><span class="p">,</span><span class="n">fscore_svm</span><span class="p">,</span><span class="n">support_svm</span><span class="o">=</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">labels_test_UP</span><span class="p">,</span><span class="n">predictions_svm</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision: </span><span class="si">{0}</span><span class="s1">, Recall: </span><span class="si">{1}</span><span class="s1">, f1-score:</span><span class="si">{2}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision_svm</span><span class="p">,</span><span class="n">recall_svm</span><span class="p">,</span><span class="n">fscore_svm</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.
  DeprecationWarning)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Best Parameters: {&#39;svc__C&#39;: 0.1, &#39;svc__kernel&#39;: &#39;linear&#39;}
Best Score: 0.6703910614525139
SVM Clasification Report:
               precision    recall  f1-score   support

  Unpleasant       0.53      0.58      0.55        31
    Pleasant       0.70      0.65      0.67        46

    accuracy                           0.62        77
   macro avg       0.61      0.62      0.61        77
weighted avg       0.63      0.62      0.63        77

Accuracy of SVM model: 0.6233766233766234
Precision: 0.6135430916552668, Recall: 0.6164095371669005, f1-score:0.6140017286084702
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Logistic Regression</span>
<span class="n">clf_lr_pip</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">Vectorizer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;logisticregression__penalty&#39;</span><span class="p">:[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">]}</span>
<span class="n">gs_cv_lr</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">clf_lr_pip</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="n">gs_cv_lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data_UP</span><span class="p">,</span> <span class="n">labels_train_UP</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Parameters: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs_cv_lr</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Score: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs_cv_lr</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>

<span class="c1"># Prediction</span>
<span class="n">predictions_lr</span> <span class="o">=</span> <span class="n">gs_cv_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data_UP</span><span class="p">)</span>

<span class="c1">#Evaluation</span>
<span class="n">report_lr</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">labels_test_UP</span><span class="p">,</span> <span class="n">predictions_lr</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Unpleasant&#39;</span><span class="p">,</span> <span class="s1">&#39;Pleasant&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;LR Clasification Report:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">report_lr</span><span class="p">))</span>

<span class="n">acc_lr</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels_test_UP</span><span class="p">,</span> <span class="n">predictions_lr</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy of LR model: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_lr</span><span class="p">))</span>

<span class="n">precision_lr</span><span class="p">,</span><span class="n">recall_lr</span><span class="p">,</span><span class="n">fscore_lr</span><span class="p">,</span><span class="n">support_lr</span><span class="o">=</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">labels_test_UP</span><span class="p">,</span><span class="n">predictions_lr</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision: </span><span class="si">{0}</span><span class="s1">, Recall: </span><span class="si">{1}</span><span class="s1">, f1-score:</span><span class="si">{2}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision_lr</span><span class="p">,</span><span class="n">recall_lr</span><span class="p">,</span><span class="n">fscore_lr</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
  warnings.warn(CV_WARNING, FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Best Parameters: {&#39;logisticregression__penalty&#39;: &#39;l1&#39;}
Best Score: 0.6983240223463687
LR Clasification Report:
               precision    recall  f1-score   support

  Unpleasant       0.59      0.52      0.55        31
    Pleasant       0.70      0.76      0.73        46

    accuracy                           0.66        77
   macro avg       0.65      0.64      0.64        77
weighted avg       0.66      0.66      0.66        77

Accuracy of LR model: 0.6623376623376623
Precision: 0.6462962962962963, Recall: 0.6384992987377279, f1-score:0.6404454022988506
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#LDA</span>
<span class="n">clf_lda_pip</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">Vectorizer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LinearDiscriminantAnalysis</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;svd&#39;</span><span class="p">))</span>
<span class="n">clf_lda_pip</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data_UP</span><span class="p">,</span><span class="n">labels_train_UP</span><span class="p">)</span>

<span class="c1">#Prediction</span>
<span class="n">predictions_lda</span> <span class="o">=</span> <span class="n">clf_lda_pip</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data_UP</span><span class="p">)</span>

<span class="c1">#Evaluation</span>
<span class="n">report_lda</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">labels_test_UP</span><span class="p">,</span> <span class="n">predictions_lda</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Unpleasant&#39;</span><span class="p">,</span> <span class="s1">&#39;Plesant&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;LDA Clasification Report:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">report_lda</span><span class="p">))</span>

<span class="n">acc_lda</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels_test_UP</span><span class="p">,</span> <span class="n">predictions_lda</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy of LDA model: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_lda</span><span class="p">))</span>

<span class="n">precision_lda</span><span class="p">,</span><span class="n">recall_lda</span><span class="p">,</span><span class="n">fscore_lda</span><span class="p">,</span><span class="n">support_lda</span><span class="o">=</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">labels_test_UP</span><span class="p">,</span><span class="n">predictions_lda</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision: </span><span class="si">{0}</span><span class="s1">, Recall: </span><span class="si">{1}</span><span class="s1">, f1-score:</span><span class="si">{2}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision_lda</span><span class="p">,</span><span class="n">recall_lda</span><span class="p">,</span><span class="n">fscore_lda</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>LDA Clasification Report:
               precision    recall  f1-score   support

  Unpleasant       0.56      0.58      0.57        31
     Plesant       0.71      0.70      0.70        46

    accuracy                           0.65        77
   macro avg       0.64      0.64      0.64        77
weighted avg       0.65      0.65      0.65        77

Accuracy of LDA model: 0.6493506493506493
Precision: 0.6368055555555556, Recall: 0.638148667601683, f1-score:0.6373626373626373
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.
  warnings.warn(&#34;Variables are collinear.&#34;)
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">acc_svm</span><span class="p">,</span> <span class="n">acc_lr</span><span class="p">,</span> <span class="n">acc_lda</span><span class="p">])</span>
<span class="n">f1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">fscore_svm</span><span class="p">,</span> <span class="n">fscore_lr</span><span class="p">,</span> <span class="n">fscore_lda</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Task-#3:-Classification-between-Neutral-and-Pleasant-Events">Task #3: Classification between Neutral and Pleasant Events<a class="anchor-link" href="#Task-#3:-Classification-between-Neutral-and-Pleasant-Events"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Dataset with neutral and pleasant events</span>
<span class="n">data_NP</span> <span class="o">=</span> <span class="n">epochs_NP</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span>
<span class="n">labels_NP</span> <span class="o">=</span> <span class="n">epochs_NP</span><span class="o">.</span><span class="n">events</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">train_data_NP</span><span class="p">,</span> <span class="n">test_data_NP</span><span class="p">,</span> <span class="n">labels_train_NP</span><span class="p">,</span> <span class="n">labels_test_NP</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data_NP</span><span class="p">,</span> <span class="n">labels_NP</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># SVM</span>
<span class="n">clf_svm_pip</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">Vectorizer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;svc__kernel&#39;</span><span class="p">:[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">],</span> <span class="s1">&#39;svc__C&#39;</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="n">gs_cv_svm</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">clf_svm_pip</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">gs_cv_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data_NP</span><span class="p">,</span> <span class="n">labels_train_NP</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Parameters: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs_cv_svm</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Score: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs_cv_svm</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>

<span class="c1"># Prediction</span>
<span class="n">predictions_svm</span> <span class="o">=</span> <span class="n">gs_cv_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data_NP</span><span class="p">)</span>

<span class="c1">#Evaluation</span>
<span class="n">report_svm</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">labels_test_NP</span><span class="p">,</span> <span class="n">predictions_svm</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Neutral&#39;</span><span class="p">,</span> <span class="s1">&#39;Pleasant&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;SVM Clasification Report:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">report_svm</span><span class="p">))</span>

<span class="n">acc_svm</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels_test_NP</span><span class="p">,</span> <span class="n">predictions_svm</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy of SVM model: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_svm</span><span class="p">))</span>

<span class="n">precision_svm</span><span class="p">,</span><span class="n">recall_svm</span><span class="p">,</span><span class="n">fscore_svm</span><span class="p">,</span><span class="n">support_svm</span><span class="o">=</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">labels_test_NP</span><span class="p">,</span><span class="n">predictions_svm</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision: </span><span class="si">{0}</span><span class="s1">, Recall: </span><span class="si">{1}</span><span class="s1">, f1-score:</span><span class="si">{2}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision_svm</span><span class="p">,</span><span class="n">recall_svm</span><span class="p">,</span><span class="n">fscore_svm</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.
  DeprecationWarning)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Best Parameters: {&#39;svc__C&#39;: 10, &#39;svc__kernel&#39;: &#39;sigmoid&#39;}
Best Score: 0.5911602209944752
SVM Clasification Report:
               precision    recall  f1-score   support

     Neutral       0.72      0.67      0.70        43
    Pleasant       0.63      0.69      0.66        35

    accuracy                           0.68        78
   macro avg       0.68      0.68      0.68        78
weighted avg       0.68      0.68      0.68        78

Accuracy of SVM model: 0.6794871794871795
Precision: 0.6782894736842104, Recall: 0.6800664451827243, f1-score:0.678164713649117
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Logistic Regression</span>
<span class="n">clf_lr_pip</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">Vectorizer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;logisticregression__penalty&#39;</span><span class="p">:[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">]}</span>
<span class="n">gs_cv_lr</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">clf_lr_pip</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="n">gs_cv_lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data_NP</span><span class="p">,</span> <span class="n">labels_train_NP</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Parameters: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs_cv_lr</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Score: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs_cv_lr</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>

<span class="c1"># Prediction</span>
<span class="n">predictions_lr</span> <span class="o">=</span> <span class="n">gs_cv_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data_NP</span><span class="p">)</span>

<span class="c1">#Evaluation</span>
<span class="n">report_lr</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">labels_test_NP</span><span class="p">,</span> <span class="n">predictions_lr</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Neutral&#39;</span><span class="p">,</span> <span class="s1">&#39;Pleasant&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;LR Clasification Report:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">report_lr</span><span class="p">))</span>

<span class="n">acc_lr</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels_test_NP</span><span class="p">,</span> <span class="n">predictions_lr</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy of LR model: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_lr</span><span class="p">))</span>

<span class="n">precision_lr</span><span class="p">,</span><span class="n">recall_lr</span><span class="p">,</span><span class="n">fscore_lr</span><span class="p">,</span><span class="n">support_lr</span><span class="o">=</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">labels_test_NP</span><span class="p">,</span><span class="n">predictions_lr</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision: </span><span class="si">{0}</span><span class="s1">, Recall: </span><span class="si">{1}</span><span class="s1">, f1-score:</span><span class="si">{2}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision_lr</span><span class="p">,</span><span class="n">recall_lr</span><span class="p">,</span><span class="n">fscore_lr</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
  warnings.warn(CV_WARNING, FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Best Parameters: {&#39;logisticregression__penalty&#39;: &#39;l1&#39;}
Best Score: 0.6243093922651933
LR Clasification Report:
               precision    recall  f1-score   support

     Neutral       0.75      0.63      0.68        43
    Pleasant       0.62      0.74      0.68        35

    accuracy                           0.68        78
   macro avg       0.68      0.69      0.68        78
weighted avg       0.69      0.68      0.68        78

Accuracy of LR model: 0.6794871794871795
Precision: 0.6845238095238095, Recall: 0.6853820598006645, f1-score:0.6794344895610718
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf_lda_pip</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">Vectorizer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LinearDiscriminantAnalysis</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;svd&#39;</span><span class="p">))</span>
<span class="n">clf_lda_pip</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data_NP</span><span class="p">,</span><span class="n">labels_train_NP</span><span class="p">)</span>

<span class="c1">#Prediction</span>
<span class="n">predictions_lda</span> <span class="o">=</span> <span class="n">clf_lda_pip</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data_NP</span><span class="p">)</span>

<span class="c1">#Evaluation</span>
<span class="n">report_lda</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">labels_test_NP</span><span class="p">,</span> <span class="n">predictions_lda</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Neutral&#39;</span><span class="p">,</span> <span class="s1">&#39;Plesant&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;LDA Clasification Report:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">report_lda</span><span class="p">))</span>

<span class="n">acc_lda</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels_test_NP</span><span class="p">,</span> <span class="n">predictions_lda</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy of LDA model: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_lda</span><span class="p">))</span>

<span class="n">precision_lda</span><span class="p">,</span><span class="n">recall_lda</span><span class="p">,</span><span class="n">fscore_lda</span><span class="p">,</span><span class="n">support_lda</span><span class="o">=</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">labels_test_NP</span><span class="p">,</span><span class="n">predictions_lda</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision: </span><span class="si">{0}</span><span class="s1">, Recall: </span><span class="si">{1}</span><span class="s1">, f1-score:</span><span class="si">{2}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision_lda</span><span class="p">,</span><span class="n">recall_lda</span><span class="p">,</span><span class="n">fscore_lda</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>LDA Clasification Report:
               precision    recall  f1-score   support

     Neutral       0.68      0.74      0.71        43
     Plesant       0.65      0.57      0.61        35

    accuracy                           0.67        78
   macro avg       0.66      0.66      0.66        78
weighted avg       0.66      0.67      0.66        78

Accuracy of LDA model: 0.6666666666666666
Precision: 0.6630061770761839, Recall: 0.6578073089700996, f1-score:0.6585858585858585
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/pinargoktepe/miniconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.
  warnings.warn(&#34;Variables are collinear.&#34;)
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">acc_svm</span><span class="p">,</span> <span class="n">acc_lr</span><span class="p">,</span> <span class="n">acc_lda</span><span class="p">])</span>
<span class="n">f1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">fscore_svm</span><span class="p">,</span> <span class="n">fscore_lr</span><span class="p">,</span> <span class="n">fscore_lda</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In order to demonstrate the accuracy values of all three tasks together, bar plot is employed as following:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">plotEvalMetrics</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">evalMetric</span><span class="p">,</span> <span class="n">metricName</span><span class="p">):</span>
    <span class="n">width</span> <span class="o">=</span> <span class="mf">0.2</span>  <span class="c1"># the width of the bars</span>

    <span class="c1"># Set position of bar on X axis</span>
    <span class="n">rects1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">evalMetric</span><span class="p">[:][</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">rects2</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">+</span> <span class="n">width</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">rects1</span><span class="p">]</span>
    <span class="n">rects3</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">+</span> <span class="n">width</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">rects2</span><span class="p">]</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">rects1</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">evalMetric</span><span class="p">))[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#87CEFA&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">rects2</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">evalMetric</span><span class="p">))[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#FFE4E1&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">rects3</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">evalMetric</span><span class="p">))[</span><span class="mi">2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#CD5C5C&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Classification Tasks&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="n">r</span> <span class="o">+</span> <span class="n">width</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">evalMetric</span><span class="p">[:][</span><span class="mi">0</span><span class="p">]))],</span> <span class="n">tasks</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">metricName</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">,</span> <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Plot Accuracies</span>
<span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;UN&#39;</span><span class="p">,</span> <span class="s1">&#39;UP&#39;</span><span class="p">,</span> <span class="s1">&#39;NP&#39;</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SVM&#39;</span><span class="p">,</span> <span class="s1">&#39;LR&#39;</span><span class="p">,</span> <span class="s1">&#39;LDA&#39;</span><span class="p">]</span>
<span class="n">plotEvalMetrics</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">accuracies</span><span class="p">,</span> <span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/Tutorial_files/ApplyingMachineLearningMethods_1_48_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Plot F1 Scores</span>
<span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;UN&#39;</span><span class="p">,</span> <span class="s1">&#39;UP&#39;</span><span class="p">,</span> <span class="s1">&#39;NP&#39;</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SVM&#39;</span><span class="p">,</span> <span class="s1">&#39;LR&#39;</span><span class="p">,</span> <span class="s1">&#39;LDA&#39;</span><span class="p">]</span>
<span class="n">plotEvalMetrics</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">f1_scores</span><span class="p">,</span> <span class="s1">&#39;F1-Scores&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/Tutorial_files/ApplyingMachineLearningMethods_1_49_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Results">Results<a class="anchor-link" href="#Results"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>On participant with id P01 data SVM, three different tasks are tested and for that, Logistic Regression (LR) and Linear Discriminant Analysis (LDA) models are built. The test accuracy values obtained from the models are provided  in the first plot above. According to the results, LDA provided the best perfromance on the first task which is classification of unpleasant and neutral events. For classification of unpleasant and pleasant events, logistic regression is the best performing model by surpassing LDA slightly. For the third task that classifies neutraland pleasant events, accuracy values are very similar. Although till now it is mentioned that certain models performed better on certain tasks, anyone could not reach above 75%.</p>
<p>Although accuracy is one of the most common evaluation metrics for machine learning models, it is not enough to conclude a model is performing than another. It may be deceptive in some cases. For example when a model classifies a majority of the instances to one class, accuracy can still be high if the classes are highly imbalanced. Another case would be when false postive and false negative have different consequences. Especially in medical domain, this case an important aspect while evaluating models. Therefore, precision, recall and f1-score, which is a metric combining precision and recall, should be considered besides accuracy.</p>
<p>F1-scores plot (second plot) demonstrates result similar to accuracy plot. So, it cannot be said that one model performing the best on all tasks and for all metrics that we calculated, values do not vary a lot.</p>

</div>
</div>
</div>
</div>

 


    </main>
    