{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial #4: Applying Machine Learning Methods to EEG Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, machine learning methods that are commonly preferred for EEG analysis will be discussed. Additionally different techinques for approaching a classification problem on eeg data will be demonstrated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset:\n",
    "As the dataset for this tutorial, 'Emotion-Antecedent Appraisal Checks:\n",
    "EEG and EMG data sets for Novelty and Pleasantness' selected. In this dataset, there are 26 participants, each have varying number of trials. There are three main categories as Target, Novel and Familar. Athough 70% of all images are in familiar category, 20% of them belongs to novel category and the rest is Target, each category has equal portion of Pleasant, Unpleasant and Neutral color images. If an image among 'Pleasant' images is selected and if it is also familiar to the participant, then the trial that is conducted with this image have 'FP' (Familiar-Pleasant) label. \n",
    "Therefore, in total there are 6 categories in this dataset. However number of categories may be changed by combining trials with the same familiarity level or the same pleasantness level. \n",
    "\n",
    "Since familar images forms the 70% of the dataset, trials with familiar pictures will be used throughout this tutorial to analyse effects of stimuli with different pleasantness levels on eeg.\n",
    "\n",
    "Note that, only one participant will be used in this tutorial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Machine Learning Methods:\n",
    "For modelling eeg data, there are three common methods: Support Vector Machines, Linear Discriminant Analysis and Logistic Regression. These methods will be employed for modeling two class problems. In the end, we will get 3 models per method.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import mne\n",
    "from mne.decoding import Vectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Models\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first step, load epoch data from file. Please note that originally, this dataset is given in csv file. However it cannot be used directly as it is with MNE library. Therefore, if you want to proceed this tutorial, firstly go through the tutorial named 'study1'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../../study1/study1_eeg/epochdata/P-01.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    1496.09 ms\n",
      "        0 CTF compensation matrices available\n",
      "484 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-a55ec86bce5e>:4: RuntimeWarning: This filename (../../study1/study1_eeg/epochdata/P-01.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs = mne.read_epochs(data_file + '.fif')\n"
     ]
    }
   ],
   "source": [
    "data_file = '../../study1/study1_eeg/epochdata/P-01'\n",
    "\n",
    "# Read the EEG epochs:\n",
    "epochs = mne.read_epochs(data_file + '.fif')\n",
    "print(len(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FU': 0, 'FN': 1, 'NP': 2, 'FP': 3, 'NU': 4, 'NN': 5}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep familiar events only. Among FU, FN and FP events, create datasets with all possible event type pairs to build models for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_UN = epochs['FU', 'FN']\n",
    "epochs_UP = epochs['FU', 'FP']\n",
    "epochs_NP = epochs['FN', 'FP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example #1:  Classification between Unpleasant and Neutral Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data and the label for the dataset with unpleasant and neutral events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with unpleasant and neutral events\n",
    "data_UN = epochs_UN.get_data()\n",
    "labels_UN = epochs_UN.events[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into two sub-datasets as training set and test set with 70 - 30 ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_UN, test_data_UN, labels_train_UN, labels_test_UN = train_test_split(data_UN, labels_UN, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the pipeline with make_pipeline() function of sklearn library. The steps should be defined in the order of execution. Apart from the classifier, Vectorizer() and StandardScaler() will be used. The purpose of using Vectorizer is to convert eeg data from (n_epochs, n_channels, n_times) structure to a vector of (samples x channels) form. \n",
    "\n",
    "After having vectorized data, StandardScaler standardizes data feature-wise by following standard score technique which has the formulation of z = (x - u) / s. In this formula, u is the mean of the feature and s is the standard deviation of the same feature. By applying this technique, each feature's mean and standard deviation will become zero and one respectively. Standardization of features, which are eeg channels in our case, prevent domination of a channel(or a feature) just becuase it contains larger variation.\n",
    "\n",
    "The final parameter of make_pipeline() will be the machine learning model. In the folowing example, the selected model is support vector machine model with rbf kernel and penalty parameter C=1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm_0 = make_pipeline(Vectorizer(), StandardScaler(), svm.SVC(kernel='rbf', C=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the hyperparameters for the classifier is determined in advance, they can be directly fixed as in above cell. However, usually it is quite difficult to determine optimal hyperparameters before testing different values for each parameter. If we test each parameter manually, we end up with another issue named overfitting. In such a case we would train the classifier with training set and test the performance on test set. So, we optimized parameters on the test set. In general, test set is smaller that training set and it may change when the trained classifier is being started to use in real systems. Therefore, having an overfitted model to test set would not provide a good generalization. \n",
    "\n",
    "For this problem cross validation would be a solution. In this approach, training set is devided into equally sized folds and trials run on different folds. In this way, hypeparameters will not be optimized on just one dataset, instead different chuncks of data will be used for hyperparameter optimization. Note that, at each trial one fold will be excluded from the training set and excluded fold will be used as test set during evaluation.\n",
    "\n",
    "For cross validation, sklearn libarary has a method cross_val_score which runs cross validation and calculates and returns the accuracy of each fold. Number of folds is parameter for this function but as a heuristic, the 5-fold or 10-fold cross validation is preferred. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 1th fold is 0.6470588235294118\n",
      "\n",
      "Accuracy of 2th fold is 0.64\n",
      "\n",
      "Accuracy of 3th fold is 0.76\n",
      "\n",
      "Accuracy of 4th fold is 0.6326530612244898\n",
      "\n",
      "Accuracy of 5th fold is 0.673469387755102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_svm_0 = make_pipeline(Vectorizer(), StandardScaler(), svm.SVC(kernel='rbf', C=1))\n",
    "scores = cross_val_score(clf_svm_0, data_UN, labels_UN, cv=5)\n",
    "for i in range(len(scores)):   \n",
    "    print('Accuracy of ' + str(i+1) + 'th fold is ' + str(scores[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is GridSearchCV which searchs the best performing parameters among the given list of possible parameter values exhaustedly. You can specify the scoring method and cross validation strategy inside GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm\n",
    "clf_svm_pip = make_pipeline(Vectorizer(), StandardScaler(), svm.SVC())\n",
    "parameters = {'svc__kernel':['linear', 'rbf', 'sigmoid'], 'svc__C':[0.1, 1, 10]}\n",
    "gs_cv_svm = GridSearchCV(clf_svm_pip, parameters, scoring='accuracy', cv=StratifiedKFold(n_splits=5), return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier by passing training data and thier labels to fit() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'svc__C': 0.1, 'svc__kernel': 'linear'}\n",
      "Best Score: 0.7011494252873564\n"
     ]
    }
   ],
   "source": [
    "gs_cv_svm.fit(train_data_UN, labels_train_UN)\n",
    "print('Best Parameters: {}'.format(gs_cv_svm.best_params_))\n",
    "print('Best Score: {}'.format(gs_cv_svm.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, evaluate the model on test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Clasification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Unpleasant       0.79      0.59      0.68        37\n",
      "     Neutral       0.68      0.84      0.75        38\n",
      "\n",
      "    accuracy                           0.72        75\n",
      "   macro avg       0.73      0.72      0.71        75\n",
      "weighted avg       0.73      0.72      0.72        75\n",
      "\n",
      "Accuracy of SVM model: 0.72\n"
     ]
    }
   ],
   "source": [
    "predictions_svm = gs_cv_svm.predict(test_data_UN)\n",
    "report_svm = classification_report(labels_test_UN, predictions_svm, target_names=['Unpleasant', 'Neutral'])\n",
    "print('SVM Clasification Report:\\n {}'.format(report_svm))\n",
    "acc_svm = accuracy_score(labels_test_UN, predictions_svm)\n",
    "print(\"Accuracy of SVM model: {}\".format(acc_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same steps can be applied to train any other machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Classification between Unpleasant and Neutral events:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above classifies unpleasant and neutral events with SVM. In the following cells, Logistic Regression and LDA will be built for the same classification task and then, performance of three different models will be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'logisticregression__penalty': 'l1'}\n",
      "Best Score: 0.7701149425287356\n",
      "LR Clasification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Unpleasant       0.74      0.62      0.68        37\n",
      "     Neutral       0.68      0.79      0.73        38\n",
      "\n",
      "    accuracy                           0.71        75\n",
      "   macro avg       0.71      0.71      0.70        75\n",
      "weighted avg       0.71      0.71      0.70        75\n",
      "\n",
      "Accuracy of LR model: 0.7066666666666667\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "clf_lr_pip = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression())\n",
    "parameters = {'logisticregression__penalty':['l1', 'l2']}\n",
    "gs_cv_lr = GridSearchCV(clf_lr_pip, parameters, scoring='accuracy')\n",
    "gs_cv_lr.fit(train_data_UN, labels_train_UN)\n",
    "\n",
    "print('Best Parameters: {}'.format(gs_cv_lr.best_params_))\n",
    "print('Best Score: {}'.format(gs_cv_lr.best_score_))\n",
    "\n",
    "predictions_lr = gs_cv_lr.predict(test_data_UN)\n",
    "report_lr = classification_report(labels_test_UN, predictions_lr, target_names=['Unpleasant', 'Neutral'])\n",
    "print('LR Clasification Report:\\n {}'.format(report_lr))\n",
    "acc_lr = accuracy_score(labels_test_UN, predictions_lr)\n",
    "print(\"Accuracy of LR model: {}\".format(acc_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Clasification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Unpleasant       0.76      0.68      0.71        37\n",
      "     Neutral       0.71      0.79      0.75        38\n",
      "\n",
      "    accuracy                           0.73        75\n",
      "   macro avg       0.74      0.73      0.73        75\n",
      "weighted avg       0.74      0.73      0.73        75\n",
      "\n",
      "Accuracy of LDA model: 0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "clf_lda_pip = make_pipeline(Vectorizer(), StandardScaler(), LinearDiscriminantAnalysis(solver='svd'))\n",
    "clf_lda_pip.fit(train_data_UN,labels_train_UN)\n",
    "\n",
    "predictions_lda = clf_lda_pip.predict(test_data_UN)\n",
    "report_lda = classification_report(labels_test_UN, predictions_lda, target_names=['Unpleasant', 'Neutral'])\n",
    "print('LDA Clasification Report:\\n {}'.format(report_lda))\n",
    "acc_lda = accuracy_score(labels_test_UN, predictions_lda)\n",
    "print(\"Accuracy of LDA model: {}\".format(acc_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of SVM = 0.72\n",
      "accuracy of LR = 0.7066666666666667\n",
      "accuracy of LDA = 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of SVM = {0}\\naccuracy of LR = {1}\\naccuracy of LDA = {2}'.format(acc_svm, acc_lr, acc_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example #2:  Classification between Unpleasant and Pleasant Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with unpleasant and pleasant events\n",
    "data_UP = epochs_UP.get_data()\n",
    "labels_UP = epochs_UP.events[:,-1]\n",
    "train_data_UP, test_data_UP, labels_train_UP, labels_test_UP = train_test_split(data_UP, labels_UP, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building SVM, LR and LDA models as in the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "SVM Clasification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Unpleasant       0.52      0.52      0.52        31\n",
      "    Pleasant       0.67      0.67      0.67        46\n",
      "\n",
      "    accuracy                           0.61        77\n",
      "   macro avg       0.60      0.60      0.60        77\n",
      "weighted avg       0.61      0.61      0.61        77\n",
      "\n",
      "Accuracy of SVM model: 0.6103896103896104\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "clf_svm_pip = make_pipeline(Vectorizer(), StandardScaler(), svm.SVC())\n",
    "parameters = {'svc__kernel':['linear', 'rbf', 'sigmoid'], 'svc__C':[0.1, 1, 10]}\n",
    "gs_cv_svm = GridSearchCV(clf_svm_pip, parameters, scoring='accuracy', cv=StratifiedKFold(n_splits=5), return_train_score=True)\n",
    "gs_cv_svm.fit(train_data_UP, labels_train_UP)\n",
    "\n",
    "print('Best Parameters: {}'.format(gs_cv_svm.best_params_))\n",
    "print('Best Score: {}'.format(gs_cv_svm.best_score_))\n",
    "\n",
    "# Make prediction\n",
    "predictions_svm = gs_cv_svm.predict(test_data_UP)\n",
    "report_svm = classification_report(labels_test_UP, predictions_svm, target_names=['Unpleasant', 'Pleasant'])\n",
    "print('SVM Clasification Report:\\n {}'.format(report_svm))\n",
    "acc_svm = accuracy_score(labels_test_UP, predictions_svm)\n",
    "print(\"Accuracy of SVM model: {}\".format(acc_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'logisticregression__penalty': 'l1'}\n",
      "Best Score: 0.6815642458100558\n",
      "LR Clasification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Unpleasant       0.61      0.61      0.61        31\n",
      "    Pleasant       0.74      0.74      0.74        46\n",
      "\n",
      "    accuracy                           0.69        77\n",
      "   macro avg       0.68      0.68      0.68        77\n",
      "weighted avg       0.69      0.69      0.69        77\n",
      "\n",
      "Accuracy of LR model: 0.6883116883116883\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf_lr_pip = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression())\n",
    "parameters = {'logisticregression__penalty':['l1', 'l2']}\n",
    "gs_cv_lr = GridSearchCV(clf_lr_pip, parameters, scoring='accuracy')\n",
    "gs_cv_lr.fit(train_data_UP, labels_train_UP)\n",
    "\n",
    "print('Best Parameters: {}'.format(gs_cv_lr.best_params_))\n",
    "print('Best Score: {}'.format(gs_cv_lr.best_score_))\n",
    "\n",
    "# Make prediction\n",
    "predictions_lr = gs_cv_lr.predict(test_data_UP)\n",
    "report_lr = classification_report(labels_test_UP, predictions_lr, target_names=['Unpleasant', 'Pleasant'])\n",
    "print('LR Clasification Report:\\n {}'.format(report_lr))\n",
    "acc_lr = accuracy_score(labels_test_UP, predictions_lr)\n",
    "print(\"Accuracy of LR model: {}\".format(acc_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Clasification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Unpleasant       0.48      0.52      0.50        31\n",
      "     Plesant       0.66      0.63      0.64        46\n",
      "\n",
      "    accuracy                           0.58        77\n",
      "   macro avg       0.57      0.57      0.57        77\n",
      "weighted avg       0.59      0.58      0.59        77\n",
      "\n",
      "Accuracy of LDA model: 0.5844155844155844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "clf_lda_pip = make_pipeline(Vectorizer(), StandardScaler(), LinearDiscriminantAnalysis(solver='svd'))\n",
    "clf_lda_pip.fit(train_data_UP,labels_train_UP)\n",
    "\n",
    "predictions_lda = clf_lda_pip.predict(test_data_UP)\n",
    "report_lda = classification_report(labels_test_UP, predictions_lda, target_names=['Unpleasant', 'Plesant'])\n",
    "print('LDA Clasification Report:\\n {}'.format(report_lda))\n",
    "acc_lda = accuracy_score(labels_test_UP, predictions_lda)\n",
    "print(\"Accuracy of LDA model: {}\".format(acc_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of SVM = 0.6103896103896104\n",
      "accuracy of LR = 0.6883116883116883\n",
      "accuracy of LDA = 0.5844155844155844\n"
     ]
    }
   ],
   "source": [
    "    print('accuracy of SVM = {0}\\naccuracy of LR = {1}\\naccuracy of LDA = {2}'.format(acc_svm, acc_lr, acc_lda))                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example #3: Classification between Neutral and Pleasant Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with neutral and pleasant events\n",
    "data_NP = epochs_NP.get_data()\n",
    "labels_NP = epochs_NP.events[:,-1]\n",
    "train_data_NP, test_data_NP, labels_train_NP, labels_test_NP = train_test_split(data_NP, labels_NP, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'svc__C': 10, 'svc__kernel': 'sigmoid'}\n",
      "Best Score: 0.6132596685082873\n",
      "SVM Clasification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Unpleasant       0.71      0.63      0.67        43\n",
      "    Pleasant       0.60      0.69      0.64        35\n",
      "\n",
      "    accuracy                           0.65        78\n",
      "   macro avg       0.66      0.66      0.65        78\n",
      "weighted avg       0.66      0.65      0.65        78\n",
      "\n",
      "Accuracy of SVM model: 0.6538461538461539\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "clf_svm_pip = make_pipeline(Vectorizer(), StandardScaler(), svm.SVC())\n",
    "parameters = {'svc__kernel':['linear', 'rbf', 'sigmoid'], 'svc__C':[0.1, 1, 10]}\n",
    "gs_cv_svm = GridSearchCV(clf_svm_pip, parameters, scoring='accuracy', cv=StratifiedKFold(n_splits=5), return_train_score=True)\n",
    "gs_cv_svm.fit(train_data_NP, labels_train_NP)\n",
    "\n",
    "print('Best Parameters: {}'.format(gs_cv_svm.best_params_))\n",
    "print('Best Score: {}'.format(gs_cv_svm.best_score_))\n",
    "\n",
    "# Make prediction\n",
    "predictions_svm = gs_cv_svm.predict(test_data_NP)\n",
    "report_svm = classification_report(labels_test_NP, predictions_svm, target_names=['Neutral', 'Pleasant'])\n",
    "print('SVM Clasification Report:\\n {}'.format(report_svm))\n",
    "acc_svm = accuracy_score(labels_test_NP, predictions_svm)\n",
    "print(\"Accuracy of SVM model: {}\".format(acc_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'logisticregression__penalty': 'l1'}\n",
      "Best Score: 0.6629834254143646\n",
      "LR Clasification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.79      0.70      0.74        43\n",
      "    Pleasant       0.68      0.77      0.72        35\n",
      "\n",
      "    accuracy                           0.73        78\n",
      "   macro avg       0.73      0.73      0.73        78\n",
      "weighted avg       0.74      0.73      0.73        78\n",
      "\n",
      "Accuracy of LR model: 0.7307692307692307\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf_lr_pip = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression())\n",
    "parameters = {'logisticregression__penalty':['l1', 'l2']}\n",
    "gs_cv_lr = GridSearchCV(clf_lr_pip, parameters, scoring='accuracy')\n",
    "gs_cv_lr.fit(train_data_NP, labels_train_NP)\n",
    "\n",
    "print('Best Parameters: {}'.format(gs_cv_lr.best_params_))\n",
    "print('Best Score: {}'.format(gs_cv_lr.best_score_))\n",
    "\n",
    "# Make prediction\n",
    "predictions_lr = gs_cv_lr.predict(test_data_NP)\n",
    "report_lr = classification_report(labels_test_NP, predictions_lr, target_names=['Neutral', 'Pleasant'])\n",
    "print('LR Clasification Report:\\n {}'.format(report_lr))\n",
    "acc_lr = accuracy_score(labels_test_NP, predictions_lr)\n",
    "print(\"Accuracy of LR model: {}\".format(acc_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Clasification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.74      0.60      0.67        43\n",
      "     Plesant       0.60      0.74      0.67        35\n",
      "\n",
      "    accuracy                           0.67        78\n",
      "   macro avg       0.67      0.67      0.67        78\n",
      "weighted avg       0.68      0.67      0.67        78\n",
      "\n",
      "Accuracy of LDA model: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pinar/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "clf_lda_pip = make_pipeline(Vectorizer(), StandardScaler(), LinearDiscriminantAnalysis(solver='svd'))\n",
    "clf_lda_pip.fit(train_data_NP,labels_train_NP)\n",
    "\n",
    "predictions_lda = clf_lda_pip.predict(test_data_NP)\n",
    "report_lda = classification_report(labels_test_NP, predictions_lda, target_names=['Neutral', 'Plesant'])\n",
    "print('LDA Clasification Report:\\n {}'.format(report_lda))\n",
    "acc_lda = accuracy_score(labels_test_NP, predictions_lda)\n",
    "print(\"Accuracy of LDA model: {}\".format(acc_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of SVM = 0.6538461538461539\n",
      "accuracy of LR = 0.7307692307692307\n",
      "accuracy of LDA = 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    " print('accuracy of SVM = {0}\\naccuracy of LR = {1}\\naccuracy of LDA = {2}'.format(acc_svm, acc_lr, acc_lda))                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
